---
title: "STAT790 HW1"
output: pdf_document
date: "2023-01-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Q1

When we have a large dataset and the data shows that it could fit a statistical model well, the data modeling culture works; however, lots of dataset do not have a statistical model pattern or it is not large enough; therefore, I believe that the algorithmic modeling culture would work better in most cases.



Q2

```{r}
library(class)
library(MLmetrics)


f_x <- function(row) 0.5*((row[1] + 1)^3)
f_x0 <- rep(0.5,100)

train.data <- function(dim){
  dim = 1:dim
  tradata = matrix(nrow = 1000, ncol = length(dim))
  for (i in dim){
    col <- runif(n = 1000 -1, 1)
    tradata[,i] <- col
  }
  training_labels = apply(tradata, 1, f_x)
  return(list(tradata, training_labels))
}


store_output <- list()
for(dim in 1:10){
  store_dimension <- list()
  for(rep in 1:100){
    output <- train.data(dim)
    training_data <- output[1][[1]]
    training_labels <- output[2][[1]]
    test_observation <- rep(0, dim)
    prdt <- knn(training_data, test_observation, training_labels, k = 1)
    store_dimension[[rep]] <- prdt
  }
  store_output[[dim]] <- store_dimension
}

mse_list <- list()
variance_list <- list()
bias_list <- list()
count <- 1
for(dim in store_output){
  f = unlist(dim)
  prediction <- as.numeric(levels(f))[f]
  mse_list[[count]] <- MSE(prediction, f_x0)
  y_hat <- mean(prediction)
  variance_list[[count]] <- MSE(prediction, rep(y_hat,100))
  bias_list[[count]] <- MSE(rep(y_hat,100), f_x0)
  count = count + 1
}

plot(unlist(mse_list), xlab = "Dimension", ylab = "MSE", col = 'red', pch = 16, main = "MSE vs. Dimension")
points(unlist(variance_list), col = 'green', pch = 16)
points(unlist(bias_list), col = 'blue', pch = 16)
lines(unlist(mse_list), col = 'red')
lines(unlist(variance_list), col = 'green')
lines(unlist(bias_list), col = 'blue')
y_legend <- max(unlist(mse_list))*0.95
legend(x = 1, y = y_legend, legend = c("MSE", "Variance", "Sq. Bias"), col = c('red', 'green', 'blue'), pch = 16)


```

```{r}
x=seq(-1,1,0.01)
plot(x,(x+1)^3/2,type="l")
abline(v=0)
```


Q3

MAE(m)=E(|Y-m|)=$E(\sqrt{(Y-m)^2)})$

We have $\frac{d MAE(\hat m)}{d \hat m}=\frac{d (\int^{\infty}_{-\infty}|Y-\hat m|f(y)dy=\int^{\hat m}_{-\infty}-(Y-\hat m)f(y)dy+\int^{\infty}_{\hat m}(Y-\hat m)f(y)dy)}{d \hat m}=0$

So we have $\int^{\hat m}_{-\infty}f(y)dy+\int^{\infty}_{\hat m}-f(y)dy=0$, therefore, $f(\hat m)=0.5$.

$\tilde \mu=median(y)$ minimize MAE instead of E(Y).

I would suggest to use MSE to measure errors, since MSE considers both Expected value and Variance of the random variable, and MAE only consider the median value of random variable. Also, the MSE emphasized on the large errors, therefore, MSE could have a better performance when there is large error occurred.

Q4

Linear smoothers: $\hat \mu(x)=\sum^{}_{i}y_{i}\hat w(x_{i},x)$

In our question, we have $\hat \mu(x)=\frac{\sum^{n}_{i}y_{i}}{n}$, therefore, $\hat w(x_{i},x)=\frac{1}{n}$ at this time.

we know that the degree of freedom is the trace of influence matrix w, where $w_{i,j}=\hat w(x_{i},x_{j})=1/n$ and w is a n*n matrix.

therefore, the degree of freedom $df(\hat \mu)=tr(w)=\sum^{n}_{i=1}\frac{1}{n}=1.$


Q5

From equation 1.55 we know that $\hat w(x_{i},x)=1/k$, when $x_{i}$ is one of the k nearest neighbours of x, and 0 otherwise.

$df(\hat \mu)=tr(w)=\sum^{n}_{i=1}w_{i,i}$, since $x_{i}=x_{i}$, which means $x_{i}$ must be one of the k nearest neighbours of $x_{i}$

$df(\hat \mu)=tr(w)=\sum^{n}_{i=1}w_{i,i}=\sum^{n}_{i=1}\frac{1}{k}=\frac{n}{k}$


Q6



```{r}
train <- zip.train
test <- zip.test

train <- train[(train$V1==2) | (train$V1==3),]
test <- test[(test$V1==2) | (test$V1==3),]


# begin with linear regression (not even logistic)
mod <- glm(V1 ~ . , data = train)

round_to_class_values <- function(value){
  if (value > 2.5) return(3)
  else (return(2))
}

pred_train <- predict(mod,train[,-1])
pred_test <- predict(mod, test[,-1])

pred_train_rounded <- sapply(pred_train, round_to_class_values)
pred_test_rounded <- sapply(pred_test, round_to_class_values)

mse_train_glm <- mean((train$V1 - pred_train_rounded)^2)
mse_test_glm <- mean((test$V1 - pred_test_rounded)^2)

# now try knn 
library(class)

K <- c(1,3,5,7,15)
store_train_mse <- list()
store_test_mse <- list()

for (k in K){
  train_pred_knn <- knn(train[,-1], train[,-1], train$V1, k = k)
  test_pred_knn <- knn(train[,-1], test[,-1], train$V1, k = k)
  
  train_pred_knn <- as.numeric(levels(train_pred_knn))[train_pred_knn]
  test_pred_knn <- as.numeric(levels(test_pred_knn))[test_pred_knn]
  
  mse_train_knn <- mean((train$V1 - train_pred_knn)^2)
  mse_test_knn <- mean((test$V1 - test_pred_knn)^2)
  
  store_train_mse <- append(store_train_mse, mse_train_knn)
  store_test_mse <- append(store_test_mse, mse_test_knn)
}


# plot results
plot(y = unlist(store_train_mse), x = K, type='b',ylim=c(0,0.06),
     col = 'red', pch = 19, xaxt = 'n', ylab = 'MSE', main = 'Training vs Test Error')
axis(side=1,at=K)
points(y = unlist(store_test_mse), x = K, type='b', col = 'blue', pch = 19)
abline(h = mse_test_glm, col = 'green')
abline(h = mse_train_glm, col = 'purple')
legend(x=11.5,y=0.06,c("KNN train MSE", "KNN test MSE", "GLM train MSE", 'GLM test MSE'), 
       col = c('red', 'blue', 'purple', 'green'))
```



```{r}
table(pred_train_rounded, train$V1)
table(pred_test_rounded, test$V1)
```












